# Vector Net
This repo works as a personal record of vector net, which serves as part of our trajectory prediction task. The dataset used is INTERACTION by MSC lab of University of California, Berkeley.

The model now is deployed to use information of HD map and all cars involved in the scene to predict the trajectory of the single agent.

The core operation to upgrade performance is to tranform the coodinate of whole graph to agent coodinate.

# Code Structure:
dataloader_osm.py defines the dataloader of the task. The extract_osm.py extract information from osm maps and encode them into embeddings.

feature.py is used to get data from csv files (segmented: frame_n = 40, frame_gap = 10, where I use 10 frames as known information to predict next 30 frames). Ihis code can find the number of shared cars in the 40 frames and use the smallest number as the final number of agents. Then it will take information of the selected agents and stores it as a npy file. The agent feature will be embedded as a 10 element vector where x,y,vx,vy, psi and other valued information can be found.

feature.py is also used to generate dictionary data. the structure looks like this: Dict{Dict{matrix}}, the key of first level dict is batch id, the key of the second level  dict is frame_id or namely time stamp; the matrix is the responding tracks and its features, it will be a two dimentional matrix. This pickle file should be a intermediate file, which is generated to help further operation.

data_pre.py is the final data processing stage before modeling. It transfers the dict generated by feature.py to a dict of structure like Dict{Dict{matrix}}, where the key of the first level dict is batch id, of the second level is track_id and the matrix size is seq_len * feature_dim

# SO HOW TO USE THE CODE:

First of all, remeber to change all absolute path to yours, sorry for the inconvinience.

Secondly, use feature.py to get data from csv files, which should be segmented by segment.py offered by interaction dataset. Notice your path!

Then, use data_pre.py to find the pickle files generated by feature.py and get final pickle data.

Finally, in main, change the pth to the final pickle data, choose the specific data you want, run the main.py 





# Undergoing
* How to make vector net dynamic?
* Make the model read in more than one file as training set

# Exeperiment
* DR-CHN-Roundabout_LN: train:0.29, val: 0.69
* DR-DEU-merging_MT: train:0.27, val 0.61
* DR-DEU-Roundabout: train:0.36, val 0.82
* DR-usa-intersection: train:0.33, val 0.59
* DR-chn-merging_SZ: train:0.34, val 0.36

The experiments are done with only one csv file fed into training phase, which means the validation performance may be promoted dramatically with more data.
# Contact
If you have any better idea of extracting infomation from HD-map to help traj prediction, please contact me:

jiefeng@berkeley.edu
